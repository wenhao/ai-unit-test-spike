## AI辅助单元测试引起的变革

#### 摘要：

单元测试的目标是确保代码组件的正确性，其作用包括验证代码正确性、发现缺陷、文档化功能、设计反馈、便于维护、提高代码质量、支持重构、提高团队信心和自动化回归测试。然而，单元测试的痛点在于编写和维护成本高、测试覆盖率难以达到理想状态、成效不够明显。

通过一系列实验，可以发现AI辅助单元测试能够成功生成符合标准的单元测试。AI辅助的单元测试带来的变革不仅限于提高测试的效率和质量，更重要的是，它改变了开发人员与单元测试活动的关系，使得单元测试成为软件开发过程中一个更加自然、透明和无感的部分。这些变革将推动软件工程实践向更高效、更智能的方向发展。

#### 关键词：AI辅助单元测试 大模型

### 单元测试的目标及痛点

#### 单元测试的目标

通过单元测试来确保和验证代码组件(通常是函数、类)的正确性。

#### 单元测试的作用

```markdown
1. 验证正确性：确保代码的每个独立部分按照预期工作，没有逻辑错误。
2. 发现缺陷：尽早发现代码中的错误和缺陷，减少它们流入后续开发阶段的风险。
3. 文档化功能：作为实际代码行为的“活”文档，帮助开发者理解代码组件应该如何工作。
4. 设计反馈：通过测试驱动开发（TDD）的方式，单元测试可以引导和改进代码设计。
5. 便于维护：当代码需要修改或重构时，单元测试可以帮助验证更改没有破坏现有功能。
6. 提高代码质量：通过持续的测试，鼓励开发者编写更清晰、更模块化的代码。
7. 支持重构：在代码重构过程中，单元测试提供了一种安全网，确保重构后的代码仍然按预期工作。
8. 提高团队信心：当单元测试覆盖率高且通过时，团队对代码的稳定性和可靠性更有信心。
9. 自动化回归测试：单元测试通常自动化运行，可以在代码变更后自动执行，确保新代码不会引入回归错误。
```

#### 单元测试的痛点

一句话总结单元测试的痛点：“投入产出比不高”。我们即不能证明单元测试有用，也不能证明单元测试没用，只能理论上觉得它还是有用的，但单元测试的编写和维护成本让人望而却步。

```markdown
1. 编写和维护成本：编写和维护单元测试需要额外的时间和资源，这可能会增加开发工作量。
2. 测试覆盖率问题：理想状态下，高测试覆盖率可以保证代码的每一个分支都被验证过，但实际上要达到高覆盖率是非常困难的。
3. 成效不够明显：对于某些特定情况，相比集成测试或UI测试，单元测试可能不够有效。
```

### AI辅助单测的成效

本着“慎始敬终”的原则，当我们对一个事情的成效不是特别有把握的时候，我们会保持谨慎观望的态度。例如，考虑到编写和维护成本，是否写单元测试这件事就值得“三思而后行”，但如果有一天，编写和维护单元测试的成本无限趋近于零的时候，写单元测试这事就会变成自然而必要的做法。AI
辅助生成单元测也许真的可以达到这个“理想国度”，以下分析将带我们一探究竟。

#### AI辅助单测的可行性

AI辅助单测是软件工程中最确定性的场景，甚至可以从辅助变成替代。相比AI辅助需求、架构设计、编码、缺陷修复等场景，单测是最确定性的场景，原因如下：

```markdown
1. 被测试的代码是确定的，AI生成单测前只需要理解被测试代码的逻辑，而且需要理解的范围较小。
2. 写单测的模式是确定的，换言之，写单测的思维链是确定不变的，步骤通常是标准化的，包含明确测试目的、准备测试数据以及设定预期结果的断言。
```

#### AI辅助单测的实验

实验应当具备明确的实验假设、实验步骤、实验结果对照，旨在测试一个或多个变量之间的关系，以验证或否定一个假设。实验设计需严谨，以确保结果的有效性和可重复性。

##### 实验假设

假设：借助AI能正确的生成单元测试，正确包含以下12个条件：

```markdown
1. [严重]正确使用JUnit框架版本。
2. [次要]正确使用AssertJ框架。
3. [严重]正确地使用Mock框架。
4. [次要]生成的单测可自动放在对应的文件目录。
5. [严重]生成的单测可编译。
6. [严重]生成的单测可执行成功。
7. [严重]正确地使用断言。
8. [重要]生成的单测测试方法名可读性高。
9. [次要]没有重复的测试。
10. [重要]测试覆盖率高。
11. [次要]重复生成结果差异小。
12. [严重]能增量生成单元测试。
```
这里衍生出一个有意思的话题：“如何评估一个AI模型的有效性？”，首先需要创建一个完备的测试库，然后通过各种测试用例来评估AI模型的有效性，如若不然，AI模型如何优化，是好是坏，两眼一抹黑。测试库的设计就是关键！

##### 实验步骤

实验对象选择了百度Comate、腾讯AI助手、通义灵码，其中以通义灵码的效果最好。因为文章篇幅有限，完整的实验请查看技术社区的文章：玩转AI辅助单测-通义灵码篇，以下简述实验步骤和结果。

#### 第1次实验：一键生成单测。

```markdown
1. 实验步骤：一键生成单测。
2. 实验结果：成功的条件有3、4、7、9，失败的条件有1、2、5、6、8、10、11、12。其他两个模型百度Comate和腾讯AI助手一键生成的结果都不佳。
3. 实验结论：也许是对AI辅助的期望太高，一键生成目前还不现实，即便是生成了手动改进的成本依然很高，甚至还不如自己手写。而且除了单测可执行之外，单测的可读性和可维护性是不可妥协的，因为单测需要随着业务逻辑的变更而变更。
```

#### 第2、3、4次实验：尝试与AI多轮对话，修复失败的条件。

第2、3、4次实验都是在不断的优化提示词来提升AI辅助单测的效果，具体每次的实验过程就不赘述了，仅列出第4次的实验结果。

```markdown
1. 实验步骤：自定义生成单测Prompt提示词，这里会用到Prompt提示词工程的各种技巧，例如One Shot、Cot思维链等，就如同教新人如何写单元测试一样。大致的提示词如下：
   * 请按以下要求生成单元测试： 
   * 请使用JUnit5、AssertJ和Mockito框架并使用MockitoAnnotations.initMocks(this)初始化。
   * 请生成一个测试方法，该方法的名称为(省略)，并且给该测试方法加上注释如下：测试意图：(省略)。
   * 该测试方法请使用以下测试数据，测试参数XXXX(键省略)为XXXX(值省略)，Mock对象XXXX(变量名省略)中的数据分别是，XXXX(键省略)为(值省略)。
   * 该测试方法请使用以下断言结果：XXXX(键省略)为XXXX(值省略)，XXXX(键省略)为XXXX(值省略)。
2. 实验结果：成功的条件有1、2、3、4、5、6、7、8、9、11、12，失败的条件有10。其中条件10可忽略不计，因为单词仅生成一个单测方法，覆盖率由人为控制。基本上证明AI辅助单测是成功的。
3. 实验结论：重新定义AI辅助单测的期望、提示词后能达成实验的假设。
```

#### 第5次实验：实现增量生成单测，并逐渐达成测试覆盖率100%的目标。

在第4次实验的基础上，增加一条提示词要求以实现增量生成单测，新增的提示词为：“生成后仅保留测试方法的内容。”。

```markdown
1. 实验步骤：自定义生成单测Prompt提示词，这里会用到Prompt提示词工程的各种技巧，例如One Shot、Cot思维链等，就如同教新人如何写单元测试一样。大致的提示词如下：
   * 请按以下要求生成单元测试： 
   * 请使用JUnit5、AssertJ和Mockito框架并使用MockitoAnnotations.initMocks(this)初始化。
   * 请生成一个测试方法，该方法的名称为(省略)，并且给该测试方法加上注释如下：测试意图：(省略)。
   * 该测试方法请使用以下测试数据，测试参数XXXX(键省略)为XXXX(值省略)，Mock对象XXXX(变量名省略)中的数据分别是，XXXX(键省略)为(值省略)。
   * 该测试方法请使用以下断言结果：XXXX(键省略)为XXXX(值省略)，XXXX(键省略)为XXXX(值省略)。
   * 生成后仅保留测试方法的内容。 
   * 生成的单元测试要符合BDD格式，包含//given、//when、//then三部分。
2. 实验结果：条件全部成功，测试覆盖率为100%。
3. 实验结论：实验是成功的！通过此提示词可以重复、标准化的在通义灵码的辅助下正确地生成单元测试，测试的质量、可读性和可维护性都达到了人工手写的标准。有人会说写这么多提示词也很花时间，如果把提示词里面的内容分成变和不变两部分内容，变的还是人工维护，不变的用工具自动化，是不是效率就很高了。
```

##### 结论

AI辅助单元测试的成功，现目前离不开以下3个关键要素：

1. 暂放弃一键生成所有单测的期望，改用增量生成单测。目前模型的能力还达不到一键生成达标的单元测试，即便是可编译可运行，但可读性和可维护性还远远达不到人工手写的标准。
2. Prompt提示词的优化。特别是写单测的Cot思维链，相当于告知AI如何把生成单测的任务分解。如同教新人如何写单元测试一样。这属于一种领域专家知识，有时也称为最佳实践。
3. AI辅助的流程要贴合开发流程。目前AI辅助单测的流程除了一键生成以外就是多轮对话的方式，多轮对话就目前还是一个很费时即成本很高的实践，有些模型还有上下文丢失、窗口大小限制的问题，所以有部分开发同学说花这时间还不如自己手写来得快。在如通义灵码这种能力的情况下，应该屏蔽更多与AI
   交互的环节跟日常开发写单测的用户旅程无缝衔接。

### AI辅助单测引起的变革

#### 第1个变革：没有单元测试

写单元测试的真正目的是希望知道代码的行为是否符合预期，这个预期一般我们是用一组业务数据和预期结果来验证的，单元测试只是一种技术手段来达成这个验证目的，倘若还有其他成本更低的手段能同样达成这个目的，单元测试就是可选的。在软件工程的领域，所有的产出都会带来对应的维护成本，极端情况下产出越少则维护成本越低。

根据上面的分析，在AI辅助的情况下生成的单元测试是能达到人工手写的标准，开发只需要设计测试用例，包括明确测试目的、准备测试数据以及设定预期结果，AI辅助完成测试用例的代码生成、执行、报告生成等，整个过程完全透明、无感。开发无需感知单元测试的存在，这是软件交付产物的变革！

#### 第2个变革：测试设计先行

在传统的软件开发流程中，单元测试往往是在代码开发完成后才开始进行的。然而，随着AI的辅助，单元测试设计的阶段也可以提前到与需求分析和设计阶段同步进行。AI可以根据需求文档和设计规格自动生成符合单元测试的用例，这些测试用例能够覆盖各种业务场景和边缘情况。

这种变革意味着开发人员在编写代码之前就已经拥有了一套完整的单元测试用例，这不仅有助于确保代码质量，还能够及时发现需求和设计中可能存在的问题。单元测试用例的先行设计还能够促进开发团队对需求的深入理解和讨论，从而提高软件的整体质量。

#### 第3个变革：自动化和持续集成的深化

AI辅助的单元测试可以无缝集成到持续集成/持续部署（CI/CD）的流程中。AI可以自动监控代码库的变化，实时生成和执行相应的单元测试用例，确保每次代码提交都不会破坏现有的功能。这种自动化的测试流程减少了人工干预，提高了软件开发的效率和可靠性。

#### 第4个变革：测试覆盖率的优化

AI辅助的单元测试可以更智能地确定测试覆盖率的目标和策略。通过分析代码的复杂性和业务逻辑的重要性，AI可以优先为关键功能生成测试用例，确保高风险区域得到充分的测试。同时，AI还可以识别过度测试的区域，减少不必要的测试用例，从而优化测试资源的分配。

#### 第5个变革：测试用例的持续学习和进化

传统的单元测试用例往往是静态的，一旦编写完成就很少发生变化。但是，AI辅助的单元测试可以具备学习和进化的能力。随着软件的迭代和功能的增加，AI可以不断学习新的业务逻辑和用户行为，自动更新和优化测试用例，确保测试用例始终与软件的最新状态保持一致。

### 总结

AI辅助的单元测试带来的变革不仅限于提高测试的效率和质量，更重要的是，它改变了开发人员与单元测试活动的关系，使得单元测试成为软件开发过程中一个更加自然、透明和无感的部分。这些变革将推动软件工程实践向更高效、更智能的方向发展。
